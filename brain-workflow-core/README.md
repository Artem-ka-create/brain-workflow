ğŸš€ Autonomous AI Agent - ĞÑ€Ñ…Ñ–Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ñ– Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ñ–Ñ
ğŸ“‹ Ğ—Ğ°Ğ³Ğ°Ğ»ÑŒĞ½Ğ¸Ğ¹ ĞĞ¿Ğ¸Ñ
Ğ¦Ğµ autonomous AI agent ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ Ñ…Ğ°ĞºĞ°Ñ‚Ğ¾Ğ½Ñƒ, ÑĞºĞ° Ğ¿Ñ€Ğ¸Ğ¹Ğ¼Ğ°Ñ” high-level user goal, ÑÑ‚Ğ²Ğ¾Ñ€ÑÑ” Ğ¿Ğ»Ğ°Ğ½ Ğ²Ğ¸ĞºĞ¾Ğ½Ğ°Ğ½Ğ½Ñ, Ñ– Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾ Ğ²Ğ¸ĞºĞ¾Ğ½ÑƒÑ” Ğ¹Ğ¾Ğ³Ğ¾ Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒÑÑ‡Ğ¸ ReAct pattern (Reasoning + Acting).

ğŸ—ï¸ ĞÑ€Ñ…Ñ–Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ¸
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     USER INPUT                              â”‚
â”‚              "Create a learning plan for..."                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 1: PLANNER AGENT                                     â”‚
â”‚  - ĞĞ½Ğ°Ğ»Ñ–Ğ·ÑƒÑ” user goal                                       â”‚
â”‚  - Ğ¡Ñ‚Ğ²Ğ¾Ñ€ÑÑ” 3-6 step Ğ¿Ğ»Ğ°Ğ½                                    â”‚
â”‚  - Ğ’Ğ¸Ğ·Ğ½Ğ°Ñ‡Ğ°Ñ” stages: question/analysis/action                â”‚
â”‚  - Output: Plan JSON                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 2: EVALUATOR                                         â”‚
â”‚  - Ğ’Ğ°Ğ»Ñ–Ğ´ÑƒÑ” Ğ¿Ğ»Ğ°Ğ½ (completeness, clarity, executability)     â”‚
â”‚  - ĞœĞ¾Ğ¶Ğµ Ğ¿Ğ¾ĞºÑ€Ğ°Ñ‰Ğ¸Ñ‚Ğ¸ Ğ¿Ğ»Ğ°Ğ½ ÑĞºÑ‰Ğ¾ Ñ” issues                       â”‚
â”‚  - Output: EvalResult (approved/improved plan)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 3: ORCHESTRATOR (Executor)                           â”‚
â”‚  - Ğ’Ğ¸ĞºĞ¾Ğ½ÑƒÑ” steps Ğ¿Ğ¾ÑĞ»Ñ–Ğ´Ğ¾Ğ²Ğ½Ğ¾                                 â”‚
â”‚  - ĞšĞµÑ€ÑƒÑ” memory (MemoryManager)                             â”‚
â”‚  - ĞŸĞµÑ€ĞµĞ´Ğ°Ñ” ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ¼Ñ–Ğ¶ steps                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                           â”‚
         â–¼                           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Step 1 â”‚    ...           â”‚ Step N â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
         â”‚                           â”‚
         â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  REACT AGENT (Ğ´Ğ»Ñ ĞºĞ¾Ğ¶Ğ½Ğ¾Ğ³Ğ¾ action step)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  ReAct Loop (max 10 iterations):                      â”‚  â”‚
â”‚  â”‚  1. THINK    â†’ LLM reasoning Ğ¿Ñ€Ğ¾ Ñ‰Ğ¾ Ñ€Ğ¾Ğ±Ğ¸Ñ‚Ğ¸ Ğ´Ğ°Ğ»Ñ–       â”‚  â”‚
â”‚  â”‚  2. DECIDE   â†’ Ğ²Ğ¸Ğ±Ñ€Ğ°Ñ‚Ğ¸ tool Ğ°Ğ±Ğ¾ final answer          â”‚  â”‚
â”‚  â”‚  3. ACT      â†’ Ğ²Ğ¸ĞºĞ¾Ğ½Ğ°Ñ‚Ğ¸ tool                          â”‚  â”‚
â”‚  â”‚  4. OBSERVE  â†’ Ñ–Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚ÑƒĞ²Ğ°Ñ‚Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚               â”‚  â”‚
â”‚  â”‚  5. EVALUATE â†’ Ñ‡Ğ¸ Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ½ÑŒĞ¾ Ğ´Ğ»Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ½Ñ?           â”‚  â”‚
â”‚  â”‚     â†“ YES â†’ synthesize result                         â”‚  â”‚
â”‚  â”‚     â†“ NO  â†’ Ğ¿Ğ¾Ğ²ĞµÑ€Ğ½ÑƒÑ‚Ğ¸ÑÑŒ Ğ´Ğ¾ ĞºÑ€Ğ¾ĞºÑƒ 1                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OBSERVER                                                   â”‚
â”‚  - ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€ÑÑ” Ñ‡Ğ¸ Ğ´Ğ¾ÑÑĞ³Ğ½ÑƒÑ‚Ğ° Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ° Ñ†Ñ–Ğ»ÑŒ                   â”‚
â”‚  - ĞœĞ¾Ğ¶Ğµ Ğ·ÑƒĞ¿Ğ¸Ğ½Ğ¸Ñ‚Ğ¸ execution Ğ´Ğ¾ÑÑ‚Ñ€Ğ¾ĞºĞ¾Ğ²Ğ¾                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FINAL RESULTS                                              â”‚
â”‚  - Execution context Ğ· ÑƒÑÑ–Ğ¼Ğ° Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸                   â”‚
â”‚  - Final output Ğ´Ğ»Ñ ĞºĞ¾Ñ€Ğ¸ÑÑ‚ÑƒĞ²Ğ°Ñ‡Ğ°                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“ Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¤Ğ°Ğ¹Ğ»Ñ–Ğ²
project/
â”œâ”€â”€ main.py                    # Ğ“Ğ¾Ğ»Ğ¾Ğ²Ğ½Ğ¸Ğ¹ entry point, orchestrator
â”œâ”€â”€ .env                       # API keys (OPENAI_API_KEY)
â”œâ”€â”€ requirements.txt           # Dependencies
â””â”€â”€ agents/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ planner.py            # Ğ¡Ñ‚Ğ²Ğ¾Ñ€ÑÑ” plan Ğ· user goal
    â”œâ”€â”€ evaluator.py          # Ğ’Ğ°Ğ»Ñ–Ğ´ÑƒÑ” Ñ– Ğ¿Ğ¾ĞºÑ€Ğ°Ñ‰ÑƒÑ” plan
    â”œâ”€â”€ executor.py           # Ğ’Ğ¸ĞºĞ¾Ğ½ÑƒÑ” plan (Orchestrator + ReAct Agent)
    â”œâ”€â”€ memory.py             # Memory management Ğ· auto-summarization
    â”œâ”€â”€ observer.py           # ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€ÑÑ” global goal completion
    â””â”€â”€ models.py             # Pydantic models (Plan, Step, EvalResult)

ğŸ“„ ĞĞ¿Ğ¸Ñ Ğ¤Ğ°Ğ¹Ğ»Ñ–Ğ²
1. main.py - Ğ“Ğ¾Ğ»Ğ¾Ğ²Ğ½Ğ¸Ğ¹ Orchestrator
Ğ©Ğ¾ Ñ€Ğ¾Ğ±Ğ¸Ñ‚ÑŒ:

Entry point Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¸
ĞĞ±'Ñ”Ğ´Ğ½ÑƒÑ” Ğ²ÑÑ– ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¸ Ğ² Ğ¾Ğ´Ğ¸Ğ½ workflow
Ğ ĞµÑ”ÑÑ‚Ñ€ÑƒÑ” tools (web_search, code_executor, file_write, data_analysis)
Ğ’Ğ¸ĞºĞ¾Ğ½ÑƒÑ” 4 Ñ„Ğ°Ğ·Ğ¸: Planning â†’ Evaluation â†’ Execution â†’ Results

ĞšĞ»ÑÑ‡Ğ¾Ğ²Ñ– ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¸:
pythonclass AutonomousAgent:
    def __init__(self):
        self.tools = setup_tools()  # Ğ ĞµÑ”ÑÑ‚Ñ€ÑƒÑ” Ğ²ÑÑ– tools
    
    def run(self, user_goal: str):
        # PHASE 1: Planning
        plan = create_plan(user_goal)
        
        # PHASE 2: Evaluation
        eval_result = evaluate_plan(user_goal, plan)
        
        # PHASE 3: Execution
        executor = Executor(tools, ask_user, observer)
        executor.run_plan(plan)
        
        # PHASE 4: Display results
        return executor.context
Tools Ñ‰Ğ¾ Ñ€ĞµÑ”ÑÑ‚Ñ€ÑƒÑÑ‚ÑŒÑÑ:

web_search - Ğ¿Ğ¾ÑˆÑƒĞº Ğ² Ñ–Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚Ñ–
code_executor - Ğ²Ğ¸ĞºĞ¾Ğ½Ğ°Ğ½Ğ½Ñ ĞºĞ¾Ğ´Ñƒ
file_write - Ğ·Ğ°Ğ¿Ğ¸Ñ Ğ² Ñ„Ğ°Ğ¹Ğ»
data_analysis - Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· Ğ´Ğ°Ğ½Ğ¸Ñ…


2. agents/planner.py - Planner Agent
Ğ©Ğ¾ Ñ€Ğ¾Ğ±Ğ¸Ñ‚ÑŒ:

ĞŸÑ€Ğ¸Ğ¹Ğ¼Ğ°Ñ” user goal (string)
ĞĞ½Ğ°Ğ»Ñ–Ğ·ÑƒÑ” Ñ‰Ğ¾ Ñ‚Ñ€ĞµĞ±Ğ° Ğ·Ñ€Ğ¾Ğ±Ğ¸Ñ‚Ğ¸
Ğ¡Ñ‚Ğ²Ğ¾Ñ€ÑÑ” structured plan (3-6 steps)
Ğ’Ğ¸Ğ·Ğ½Ğ°Ñ‡Ğ°Ñ” Ğ´Ğ»Ñ ĞºĞ¾Ğ¶Ğ½Ğ¾Ğ³Ğ¾ step: stage, instruction, dependencies

Stages:

question - Ğ¿Ğ¸Ñ‚Ğ°Ğ½Ğ½Ñ ĞºĞ¾Ñ€Ğ¸ÑÑ‚ÑƒĞ²Ğ°Ñ‡Ñƒ (ÑĞºÑ‰Ğ¾ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ¾ Ğ½ĞµĞ¾Ğ±Ñ…Ñ–Ğ´Ğ½Ğ¾)
analysis - Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· Ğ´Ğ°Ğ½Ğ¸Ñ…, Ğ¾Ğ±Ñ€Ğ¾Ğ±ĞºĞ° Ñ–Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ñ–Ñ—
action - ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ° Ğ´Ñ–Ñ (search, generate, write file)

Output: Plan object Ğ· ÑĞ¿Ğ¸ÑĞºĞ¾Ğ¼ Step
ĞÑĞ¾Ğ±Ğ»Ğ¸Ğ²Ğ¾ÑÑ‚Ñ–:

Domain-agnostic (Ğ¿Ñ€Ğ°Ñ†ÑÑ” Ğ´Ğ»Ñ Ğ±ÑƒĞ´ÑŒ-ÑĞºĞ¾Ñ— Ğ·Ğ°Ğ´Ğ°Ñ‡Ñ–)
ĞœÑ–Ğ½Ñ–Ğ¼Ñ–Ğ·ÑƒÑ” questions (autonomous approach)
tool Ğ¼Ğ¾Ğ¶Ğµ Ğ±ÑƒÑ‚Ğ¸ null â†’ ReAct agent ÑĞ°Ğ¼ Ğ²Ğ¸Ñ€Ñ–ÑˆÑƒÑ” ÑĞºĞ¸Ğ¹ tool Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ°Ñ‚Ğ¸
Encoding fix Ğ´Ğ»Ñ Unicode surrogates


3. agents/evaluator.py - Plan Evaluator
Ğ©Ğ¾ Ñ€Ğ¾Ğ±Ğ¸Ñ‚ÑŒ:

ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€ÑÑ” ÑĞºÑ–ÑÑ‚ÑŒ ÑÑ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ»Ğ°Ğ½Ñƒ
ĞÑ†Ñ–Ğ½ÑÑ” Ğ·Ğ° 7 ĞºÑ€Ğ¸Ñ‚ĞµÑ€Ñ–ÑĞ¼Ğ¸:

Completeness - Ñ‡Ğ¸ Ğ¿Ğ¾ĞºÑ€Ğ¸Ğ²Ğ°Ñ” Ğ²ÑÑ– ĞºÑ€Ğ¾ĞºĞ¸?
Clarity - Ñ‡Ğ¸ Ñ‡Ñ–Ñ‚ĞºÑ– Ñ–Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ñ–Ñ—?
Stages - Ñ‡Ğ¸ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾ Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ°Ğ½Ñ–?
Step count - Ñ‡Ğ¸ 3-6 steps?
Dependencies - Ñ‡Ğ¸ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ– Ğ·Ğ°Ğ»ĞµĞ¶Ğ½Ğ¾ÑÑ‚Ñ–?
Executability - Ñ‡Ğ¸ Ğ¼Ğ¾Ğ¶Ğµ autonomous agent Ğ²Ğ¸ĞºĞ¾Ğ½Ğ°Ñ‚Ğ¸?
Autonomy - Ñ‡Ğ¸ Ğ¼Ñ–Ğ½Ñ–Ğ¼Ñ–Ğ·Ğ¾Ğ²Ğ°Ğ½Ñ– Ğ¿Ğ¸Ñ‚Ğ°Ğ½Ğ½Ñ ĞºĞ¾Ñ€Ğ¸ÑÑ‚ÑƒĞ²Ğ°Ñ‡Ñƒ?



Output: EvalResult Ğ·:

is_good: bool - Ñ‡Ğ¸ Ğ¿Ğ»Ğ°Ğ½ ĞĞš
verdict: str - Ğ¿Ğ¾ÑÑĞ½ĞµĞ½Ğ½Ñ
confidence: float - Ğ²Ğ¿ĞµĞ²Ğ½ĞµĞ½Ñ–ÑÑ‚ÑŒ 0-1
improved_plan: Plan | None - Ğ¿Ğ¾ĞºÑ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ»Ğ°Ğ½ ÑĞºÑ‰Ğ¾ Ñ‚Ñ€ĞµĞ±Ğ°


4. agents/executor.py - Orchestrator + ReAct Agent
ĞĞ°Ğ¹Ğ²Ğ°Ğ¶Ğ»Ğ¸Ğ²Ñ–ÑˆĞ¸Ğ¹ Ñ„Ğ°Ğ¹Ğ»! ĞœÑ–ÑÑ‚Ğ¸Ñ‚ÑŒ 2 ĞºĞ»Ğ°ÑĞ¸:
A. ReactAgent - Autonomous Executor
Ğ©Ğ¾ Ñ€Ğ¾Ğ±Ğ¸Ñ‚ÑŒ:

Ğ’Ğ¸ĞºĞ¾Ğ½ÑƒÑ” Ğ¾ĞºÑ€ĞµĞ¼Ğ¸Ğ¹ step Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾
Ğ’Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒÑ” ReAct loop (max 10 iterations)
Ğ¡Ğ°Ğ¼ Ğ²Ğ¸Ñ€Ñ–ÑˆÑƒÑ” ÑĞºÑ– tools Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ°Ñ‚Ğ¸
Ğ¡Ğ°Ğ¼ Ğ¿ĞµÑ€ĞµĞ²Ñ–Ñ€ÑÑ” ĞºĞ¾Ğ»Ğ¸ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾

ReAct Loop (5 ĞºÑ€Ğ¾ĞºÑ–Ğ²):
pythonfor iteration in range(max_iterations):
    # 1. THINK (Reasoning)
    thought = self._reason(memory, iteration)
    # LLM Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·ÑƒÑ”: Ñ‰Ğ¾ Ğ·Ñ€Ğ¾Ğ±Ğ»ĞµĞ½Ğ¾? Ñ‰Ğ¾ Ñ‚Ñ€ĞµĞ±Ğ° Ğ´Ğ°Ğ»Ñ–?
    
    # 2. DECIDE ACTION
    action = self._decide_action(thought, memory)
    # LLM Ğ²Ğ¸Ğ±Ğ¸Ñ€Ğ°Ñ”: use_tool Ğ°Ğ±Ğ¾ final_answer
    
    # 3. ACT (Execute)
    result = self._execute_action(action)
    # Ğ’Ğ¸ĞºĞ¾Ğ½ÑƒÑ” Ğ¾Ğ±Ñ€Ğ°Ğ½Ğ¸Ğ¹ tool
    
    # 4. OBSERVE
    observation = self._observe(result, step)
    # LLM Ñ–Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚ÑƒÑ” Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
    
    # 5. EVALUATE
    is_complete = self._evaluate_completion(step, memory)
    # LLM Ğ¿ĞµÑ€ĞµĞ²Ñ–Ñ€ÑÑ”: Ñ‡Ğ¸ Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ½ÑŒĞ¾ Ğ´Ğ»Ñ Ğ²Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´Ñ–?
    
    if is_complete:
        return self._synthesize_final_result(memory)
ĞšĞ»ÑÑ‡Ğ¾Ğ²Ğ° Ğ¾ÑĞ¾Ğ±Ğ»Ğ¸Ğ²Ñ–ÑÑ‚ÑŒ: Autonomous! ĞĞµ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ²Ğ¸ĞºĞ»Ğ¸ĞºĞ°Ñ” tool Ğ¾Ğ´Ğ¸Ğ½ Ñ€Ğ°Ğ·, Ğ° Ğ´ÑƒĞ¼Ğ°Ñ” â†’ Ğ´Ñ–Ñ” â†’ Ğ¾Ñ†Ñ–Ğ½ÑÑ” â†’ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€ÑÑ” Ğ´Ğ¾ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ½Ñ.
B. Executor - Orchestrator
Ğ©Ğ¾ Ñ€Ğ¾Ğ±Ğ¸Ñ‚ÑŒ:

ĞšĞµÑ€ÑƒÑ” Ğ²Ğ¸ĞºĞ¾Ğ½Ğ°Ğ½Ğ½ÑĞ¼ Ğ²ÑÑŒĞ¾Ğ³Ğ¾ Ğ¿Ğ»Ğ°Ğ½Ñƒ
Ğ’Ğ¸ĞºĞ»Ğ¸ĞºĞ°Ñ” Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¸Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ´Ğ»Ñ ĞºĞ¾Ğ¶Ğ½Ğ¾Ğ³Ğ¾ stage:

_run_question_step() â†’ Ğ¿Ğ¸Ñ‚Ğ°Ñ” ĞºĞ¾Ñ€Ğ¸ÑÑ‚ÑƒĞ²Ğ°Ñ‡Ğ°
_run_analysis_step() â†’ LLM Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·
_run_action_step() â†’ ReAct Agent


ĞŸĞµÑ€ĞµĞ´Ğ°Ñ” ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ¼Ñ–Ğ¶ steps
Ğ’Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒÑ” MemoryManager Ğ´Ğ»Ñ Ğ²ĞµĞ»Ğ¸ĞºĞ¸Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ–Ğ²
Ğ’Ğ¸ĞºĞ»Ğ¸ĞºĞ°Ñ” Observer Ğ¿Ñ–ÑĞ»Ñ ĞºĞ¾Ğ¶Ğ½Ğ¾Ğ³Ğ¾ step

Memory Integration:

Ğ—Ğ±ĞµÑ€Ñ–Ğ³Ğ°Ñ” Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¸ Ğ² MemoryManager
ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ğ¾ ÑÑ‚Ğ²Ğ¾Ñ€ÑÑ” summaries Ğ´Ğ»Ñ Ğ²ĞµĞ»Ğ¸ĞºĞ¸Ñ… outputs (>3000 chars)
ĞŸĞµÑ€ĞµĞ´Ğ°Ñ” relevant context Ğ² ReAct Agent


5. agents/memory.py - Memory Management
2 ĞºĞ»Ğ°ÑĞ¸:
A. MemoryManager
Ğ©Ğ¾ Ñ€Ğ¾Ğ±Ğ¸Ñ‚ÑŒ:

Ğ—Ğ±ĞµÑ€Ñ–Ğ³Ğ°Ñ” execution context (Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¸ Ğ²ÑÑ–Ñ… steps)
ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ğ¾ ÑÑ‚Ğ²Ğ¾Ñ€ÑÑ” summaries Ğ´Ğ»Ñ Ğ²ĞµĞ»Ğ¸ĞºĞ¸Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ–Ğ²
ĞĞ°Ğ´Ğ°Ñ” relevant context Ğ´Ğ»Ñ ĞºĞ¾Ğ¶Ğ½Ğ¾Ğ³Ğ¾ step (Ğ½Ğµ Ğ²ĞµÑÑŒ context!)

ĞœĞµÑ‚Ğ¾Ğ´Ğ¸:
pythonmemory.store(key, value)
# â†’ ÑĞºÑ‰Ğ¾ value > 3000 chars, ÑÑ‚Ğ²Ğ¾Ñ€ÑÑ” summary

memory.get(key)
# â†’ Ğ¿Ğ¾Ğ²ĞµÑ€Ñ‚Ğ°Ñ” Ğ¿Ğ¾Ğ²Ğ½Ğ¸Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚

memory.get_for_context(key)
# â†’ Ğ¿Ğ¾Ğ²ĞµÑ€Ñ‚Ğ°Ñ” summary ÑĞºÑ‰Ğ¾ Ñ”, Ñ–Ğ½Ğ°ĞºÑˆĞµ Ğ¿Ğ¾Ğ²Ğ½Ğ¸Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚

memory.get_relevant_context(required_keys)
# â†’ Ğ¿Ğ¾Ğ²ĞµÑ€Ñ‚Ğ°Ñ” Ñ‚Ñ–Ğ»ÑŒĞºĞ¸ Ğ¿Ğ¾Ñ‚Ñ€Ñ–Ğ±Ğ½Ñ– ĞºĞ»ÑÑ‡Ñ– (Ğ´Ğ»Ñ ReAct Agent)

memory.get_context_stats()
# â†’ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°: keys, size, summarized_keys
ĞĞ°Ğ²Ñ–Ñ‰Ğ¾ Ñ‚Ñ€ĞµĞ±Ğ°:

ReAct Agent Ğ¾Ñ‚Ñ€Ğ¸Ğ¼ÑƒÑ” ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ· Ğ¿Ğ¾Ğ¿ĞµÑ€ĞµĞ´Ğ½Ñ–Ñ… steps
Ğ¯ĞºÑ‰Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ²ĞµĞ»Ğ¸ĞºĞ¸Ğ¹ â†’ LLM context overflow
Summary Ğ²Ğ¸Ñ€Ñ–ÑˆÑƒÑ” Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ: ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ° Ğ²ĞµÑ€ÑÑ–Ñ Ğ·Ğ°Ğ¼Ñ–ÑÑ‚ÑŒ Ğ¿Ğ¾Ğ²Ğ½Ğ¾Ñ—

B. ConversationMemory (optional)
Ğ©Ğ¾ Ñ€Ğ¾Ğ±Ğ¸Ñ‚ÑŒ:

Ğ—Ğ±ĞµÑ€Ñ–Ğ³Ğ°Ñ” Ñ–ÑÑ‚Ğ¾Ñ€Ñ–Ñ Ñ€Ğ¾Ğ·Ğ¼Ğ¾Ğ²Ğ¸ (chat history)
Ğ”Ğ»Ñ multi-turn dialogue (ÑĞºÑ‰Ğ¾ Ñ‚Ñ€ĞµĞ±Ğ° follow-up)

Ğ”Ğ»Ñ Ñ…Ğ°ĞºĞ°Ñ‚Ğ¾Ğ½Ñƒ: Ğ½Ğµ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ¾, MemoryManager Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ½ÑŒĞ¾.

6. agents/observer.py - Goal Achievement Monitor
Ğ©Ğ¾ Ñ€Ğ¾Ğ±Ğ¸Ñ‚ÑŒ:

ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€ÑÑ” Ñ‡Ğ¸ Ğ´Ğ¾ÑÑĞ³Ğ½ÑƒÑ‚Ğ° Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ° Ñ†Ñ–Ğ»ÑŒ
Ğ’Ğ¸ĞºĞ»Ğ¸ĞºĞ°Ñ”Ñ‚ÑŒÑÑ Ğ¿Ñ–ÑĞ»Ñ ĞºĞ¾Ğ¶Ğ½Ğ¾Ğ³Ğ¾ step
ĞœĞ¾Ğ¶Ğµ Ğ·ÑƒĞ¿Ğ¸Ğ½Ğ¸Ñ‚Ğ¸ execution Ğ´Ğ¾ÑÑ‚Ñ€Ğ¾ĞºĞ¾Ğ²Ğ¾

ĞŸĞ¾Ñ‚Ğ¾Ñ‡Ğ½Ğ° Ñ€ĞµĞ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ (simple):
pythondef simple_observer(plan, step_index, context):
    # Ğ¯ĞºÑ‰Ğ¾ Ğ¾ÑÑ‚Ğ°Ğ½Ğ½Ñ–Ğ¹ step â†’ stop
    if step_index == len(plan.steps) - 1:
        return True
    
    # Ğ¯ĞºÑ‰Ğ¾ Ñ” ÑĞ¿ĞµÑ†Ñ–Ğ°Ğ»ÑŒĞ½Ğ¸Ğ¹ ĞºĞ»ÑÑ‡ â†’ stop
    if "final_workout_plan" in context:
        return True
    
    return False
ĞœĞ¾Ğ¶Ğ½Ğ° Ğ¿Ğ¾ĞºÑ€Ğ°Ñ‰Ğ¸Ñ‚Ğ¸:

LLM-based observer Ñ‰Ğ¾ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·ÑƒÑ” Ñ‡Ğ¸ goal achieved
ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€ÑÑ” quality Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñƒ
Ğ’Ğ¸Ñ€Ñ–ÑˆÑƒÑ” Ñ‡Ğ¸ Ñ‚Ñ€ĞµĞ±Ğ° Ñ‰Ğµ steps


7. agents/models.py - Data Models
Pydantic models Ğ´Ğ»Ñ type safety:
Step
pythonclass Step(BaseModel):
    id: str                        # "step_1"
    stage: "question|analysis|action"
    title: str                     # "Research requirements"
    instruction: str               # Ñ‰Ğ¾ Ñ€Ğ¾Ğ±Ğ¸Ñ‚Ğ¸
    depends_on: List[str]          # ["step_1", "step_2"]
    tool: Optional[str]            # "web_search" Ğ°Ğ±Ğ¾ null
    expected_input_keys: List[str] # ÑĞºÑ– keys Ğ· context Ñ‚Ñ€ĞµĞ±Ğ°
    output_key: Optional[str]      # ĞºÑƒĞ´Ğ¸ Ğ·Ğ±ĞµÑ€ĞµĞ³Ñ‚Ğ¸ result
Plan
pythonclass Plan(BaseModel):
    goal: str                      # original user goal
    domain: str                    # "research", "coding", etc.
    steps: List[Step]              # 3-6 steps
    
    # Helper methods:
    def get_step_by_id(step_id) -> Step
    def get_dependencies_for_step(step_id) -> List[Step]
EvalResult
pythonclass EvalResult(BaseModel):
    is_good: bool                  # Ñ‡Ğ¸ Ğ¿Ğ»Ğ°Ğ½ OK
    verdict: str                   # Ğ¿Ğ¾ÑÑĞ½ĞµĞ½Ğ½Ñ
    improved_plan: Optional[Plan]  # Ğ¿Ğ¾ĞºÑ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ»Ğ°Ğ½
    confidence: float              # 0.0 - 1.0

ğŸ”„ Flow Execution (ĞŸÑ€Ğ¸ĞºĞ»Ğ°Ğ´)
User Goal: "Research AI trends and create a report"
PHASE 1: Planning
json{
  "goal": "Research AI trends and create a report",
  "domain": "research",
  "steps": [
    {
      "id": "step_1",
      "stage": "action",
      "title": "Research AI trends",
      "instruction": "Search for latest AI trends in 2024",
      "tool": null,
      "output_key": "research_results"
    },
    {
      "id": "step_2",
      "stage": "analysis",
      "title": "Analyze trends",
      "instruction": "Categorize and summarize key trends",
      "expected_input_keys": ["research_results"],
      "output_key": "trend_summary"
    },
    {
      "id": "step_3",
      "stage": "action",
      "title": "Generate report",
      "instruction": "Create structured report document",
      "expected_input_keys": ["trend_summary"],
      "output_key": "final_report"
    }
  ]
}
```

### PHASE 2: Evaluation
```
Verdict: "Plan is well-structured with clear sequential steps..."
is_good: True
```

### PHASE 3: Execution

**Step 1 (action) â†’ ReAct Agent:**
```
Iteration 1:
  ğŸ’­ THINK: "Need to search for AI trends 2024"
  ğŸ”§ ACT: web_search("AI trends 2024")
  ğŸ‘ï¸ OBSERVE: "Found articles about LLMs, multimodal AI..."
  ğŸ” EVAL: NO - need more specific data

Iteration 2:
  ğŸ’­ THINK: "Need more specific areas"
  ğŸ”§ ACT: web_search("computer vision breakthroughs 2024")
  ğŸ‘ï¸ OBSERVE: "Found CV advancements..."
  ğŸ” EVAL: YES - sufficient data âœ…

Result â†’ context["research_results"]
```

**Step 2 (analysis) â†’ LLM Analysis:**
```
Analyzes research_results â†’ creates structured summary
Result â†’ context["trend_summary"]
```

**Step 3 (action) â†’ ReAct Agent:**
```
Iteration 1:
  ğŸ’­ THINK: "Need to format as report"
  ğŸ”§ ACT: file_write(filename="ai_trends_report.md", content=...)
  ğŸ‘ï¸ OBSERVE: "File written successfully"
  ğŸ” EVAL: YES âœ…

Result â†’ context["final_report"]
```

### PHASE 4: Results
```
Final output: "ai_trends_report.md created with comprehensive AI trends analysis"

ğŸ”‘ ĞšĞ»ÑÑ‡Ğ¾Ğ²Ñ– Ğ’Ñ–Ğ´Ğ¼Ñ–Ğ½Ğ½Ğ¾ÑÑ‚Ñ– Ğ²Ñ–Ğ´ Ğ—Ğ²Ğ¸Ñ‡Ğ°Ğ¹Ğ½Ğ¾Ğ³Ğ¾ Chatbot
Ğ—Ğ²Ğ¸Ñ‡Ğ°Ğ¹Ğ½Ğ¸Ğ¹ ChatbotAutonomous AgentĞĞ´Ğ¸Ğ½ LLM call â†’ Ğ²Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´ÑŒĞŸĞ»Ğ°Ğ½ â†’ Ğ¼Ğ½Ğ¾Ğ¶Ğ¸Ğ½Ğ° autonomous stepsĞĞµĞ¼Ğ°Ñ” planningPlanner ÑÑ‚Ğ²Ğ¾Ñ€ÑÑ” structured planĞĞµĞ¼Ğ°Ñ” self-evaluationEvaluator Ğ¿ĞµÑ€ĞµĞ²Ñ–Ñ€ÑÑ” Ğ¿Ğ»Ğ°Ğ½ĞŸÑ€Ğ¾ÑÑ‚Ğ¸Ğ¹ tool call (Ğ¾Ğ´Ğ¸Ğ½ Ñ€Ğ°Ğ·)ReAct loop (thinking + retries)ĞĞµĞ¼Ğ°Ñ” memory Ğ¼Ñ–Ğ¶ callsMemoryManager Ğ· auto-summarizationĞŸĞ¾Ñ‚Ñ€ĞµĞ±ÑƒÑ” follow-up Ğ¿Ğ¸Ñ‚Ğ°Ğ½ÑŒAutonomous execution Ğ´Ğ¾ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ½Ñ

ğŸš€ Ğ—Ğ°Ğ¿ÑƒÑĞº
bash# 1. Install dependencies
pip install langchain langchain-openai python-dotenv pydantic

# 2. Set up .env
echo "OPENAI_API_KEY=your_key" > .env

# 3. Run
python main.py
```

**Input:**
```
Enter your goal: Research Python best practices and create a guide
```

**Output:**
```
âœ… Tools registered: ['web_search', 'code_executor', ...]
ğŸ§  MemoryManager enabled

ğŸ¯ PHASE 1: PLANNING
âœ… Plan created with 4 steps

ğŸ” PHASE 2: EVALUATION
âœ… Plan approved

âš™ï¸ PHASE 3: EXECUTION
[STEP 1/4] Research Python practices (action)
  ğŸ¤– ReAct Agent executing...
  ğŸ’­ THOUGHT: Need to search...
  ...
âœ… Step completed

ğŸ“Š PHASE 4: RESULTS
ğŸ¯ FINAL RESULT: [guide content]

ğŸ’¡ Ğ©Ğ¾ Ğ Ğ¾Ğ±Ğ¸Ñ‚ÑŒ Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ñƒ "Autonomous"

Planning - ÑĞ°Ğ¼ Ñ€Ğ¾Ğ·Ğ±Ğ¸Ğ²Ğ°Ñ” goal Ğ½Ğ° steps
Self-evaluation - Ğ¿ĞµÑ€ĞµĞ²Ñ–Ñ€ÑÑ” Ñ‡Ğ¸ plan Ğ»Ğ¾Ğ³Ñ–Ñ‡Ğ½Ğ¸Ğ¹
ReAct Loop - Ğ´ÑƒĞ¼Ğ°Ñ” â†’ Ğ´Ñ–Ñ” â†’ Ğ¾Ñ†Ñ–Ğ½ÑÑ” â†’ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€ÑÑ”
Tool Selection - ÑĞ°Ğ¼ Ğ²Ğ¸Ğ±Ğ¸Ñ€Ğ°Ñ” ÑĞºÑ– tools Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ°Ñ‚Ğ¸
Completion Detection - ÑĞ°Ğ¼ Ğ·Ğ½Ğ°Ñ” ĞºĞ¾Ğ»Ğ¸ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾
Error Recovery - ÑĞºÑ‰Ğ¾ tool fails, Ğ¿Ñ€Ğ¾Ğ±ÑƒÑ” Ñ–Ğ½Ğ°ĞºÑˆĞµ
Memory Management - ĞºĞµÑ€ÑƒÑ” ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ğ¾


ğŸ“Š Dependencies
txtlangchain
langchain-openai
python-dotenv
pydantic
openai